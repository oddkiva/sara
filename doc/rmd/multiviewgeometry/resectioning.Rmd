## Pose Recovery

The pose recovery is another important problem that is solved in
Structure-from-Motion. The pose recovery can be tackled differently depending on
the situations we are in. They are two situations that I have found in my
current understanding.

### Problem Statement

The pose recovery assumes that a set of 2D image points $\{ \mathbf{u}_i \}_i$
in an image $I$ are known to respectively correspond to a set of 3D scene points
$\{ \mathbf{x}_i\}$ in some reference frame.

Our goal is to retrieve the camera parameters that formed this very image $I$,
namely the camera pose, that is its gaze orientation $\mathbf{R}$ and position
$\mathbf{t}$ with respect to a reference frame, say, an arbitrary world frame
$\mathcal{W}$.

:::fyi
In case we are still being confused about which frame or coordinates, let us
remind again that

- the 2D image points $\mathbf{u}_i$ are the pixel coordinates in the image $I$,
- the 3D scene points $\mathbf{x}_i$ have their coordinates expressed in the
  world frame $\mathcal{W}$.
:::


There are two situations in Structure-from-Motion:

1. we do not know the camera intrinsic parameters but we do know that the
   mathematical camera model that can explain the formation of image $I$ is
   either the pinhole camera model, or a camera model that can account for
   small distortion;
2. we are dealing with calibrated camers, that is, we do know which mathematical
   camera model explains best the formation of image $I$ and we know its
   associated parameter values of this model.

### First Situation: Camera Resectioning

The first situation can be solved by means of standard linear algebra.
Specifically the calibration software Bundler [@SnavelySS:2008:ijcv] uses
[@HartleyZ:2003:mvg]'s Direct Linear Transform (DLT) method to find a good guess
of the camera pose. After which, a bundle adjustment procedure refines the pose
$(\mathbf{R}, \mathbf{t})$ of the camera and its intrinsic parameters, which
include the calibration matrix $\mathbf{K}$ and the distortion coefficients.

### Second Situation: Perspective-n-Point

In the second situation, we know the camera model and its associated parameter
values. As a result, we can calculate the incident light ray vector
$\mathrm{ray}(\mathbf{u}_i) = \mathbf{y}_i \in \mathbb{R}^3$ that has hit the
image plane at any pixel coordinates $\mathbf{u}_i$. The backprojected ray
$\mathbf{y}_i$ has its coordinates expressed in the camera frame $\mathcal{C}$.

For example, if we are dealing with the simple pinhole camera model with known
calibration matrix $\mathbf{K}$, the film (homogeneous) coordinates

\begin{equation}
  \begin{bmatrix} \tilde{\mathbf{u}}_i \\ 1 \end{bmatrix} =
  \mathbf{K}^{-1} \begin{bmatrix} \mathbf{u}_i \\ 1 \end{bmatrix}
\end{equation}

is also the backprojected light ray vector $\mathbf{y}_i$ from a physics point
of view.

Now the goal is to calculate the camera pose $(\mathbf{R}, \mathbf{t})$ given
that we know that each backprojected light ray $\mathbf{y}_i$ respectively
corresponds to the scene point $\mathbf{x}_i$. This is how the
Perspective-n-Point (PnP) problem is formulated.

The PnP problem starts by observing that any rigid body motion $(\mathbf{R},
\mathbf{t})$ preserves the Euclidean distance $||\mathbf{x}_i -
\mathbf{x}_j||_2$ for any pair of 3D scene points $\mathbf{x}_i$ and
$\mathbf{x}_j$ for any $i \neq j$. In words, denoting the transformed point by
any such rigid body motion by

\begin{equation}
  \mathbf{x}'_i = \mathbf{R} \mathbf{x}_i + \mathbf{t}
\end{equation}

the following equality holds

\begin{equation}
  ||\mathbf{x}'_i - \mathbf{x}'_j||_2= ||\mathbf{x}_i - \mathbf{x}_j||_2
\end{equation}

In particular the distance invariance still holds for the camera pose we aim at
calculating.

:::fyi
Let us ponder for a moment about the meaning of the global rigid motion equation
above. Notice here that in the PnP problem formulation:

- $\mathbf{R}$ actually expresses the axes of the world frame $\mathcal{W}$ with
  respect to the camera frame $\mathcal{C}$.
- $\mathbf{t}$ actually expresses the position of the world origin in the camera
  frame $\mathcal{C}$.

Not the other way around.
:::

In our context, $\mathbf{x}'_i$ is a the same 3D scene point $\mathbf{x}_i$ but
this time it is expressed in the camera frame $\mathcal{C}$.  And following the
basic laws of geometrical optics, the 3D coordinates $\mathbf{x}'_i$ is
collinear to the backprojected light ray vector $\mathbf{y}_i$

\begin{equation}
  \mathbf{x}'_i = \lambda_i \mathbf{y}_i,
\end{equation}

with the additional physics constraint that each scale must be positive
\begin{equation}
  \lambda_i > 0,
\end{equation}
which ensures that the 3D scene point $\mathbf{x}'_i$ does appear in front of the
camera.


The camera resectioning then consists in determining the appropriate scale
$\lambda_i$ to each backprojected ray $\mathbf{y}_i$ so that the change of
coordinate via the rigid body motion $(\mathbf{R}, \mathbf{t})$ still preserves
the distances.

\begin{equation}
  ||\lambda_i \mathbf{y}_i - \lambda_j \mathbf{y}_j||_2 =
  ||\mathbf{x}_i - \mathbf{x}_j||_2
\end{equation}

Let us assume for a moment that we know each scale $\lambda_i$. Then we are able
to completely determine the rotation $\mathbf{R}$, by forming three direction
vectors

\begin{equation}
  \left\{
  \begin{array}{c}
    \mathbf{z}_{01} = \lambda_0 \mathbf{y}_0 - \lambda_1 \mathbf{y}_1 \\
    \mathbf{z}_{02} = \lambda_0 \mathbf{y}_0 - \lambda_2 \mathbf{y}_2 \\
    \mathbf{z}_{12} = \lambda_1 \mathbf{y}_1 - \lambda_2 \mathbf{y}_2
  \end{array}
  \right.,
\end{equation}

These direction vectors are fully determined as the scales $\lambda_i$ are
known. And because we know that

\begin{equation}
  \lambda_i \mathbf{y}_i = \mathbf{R} \mathbf{x}_i + \mathbf{t},
\end{equation}

By plugging these equalities into, these three direction vectors $\mathbf{z}_{ij}$
also satisfy the matrix-vector product

\begin{equation}
  \mathbf{z}_{ij} = \mathbf{R} (\mathbf{x}_i - \mathbf{x}_j)
\end{equation}

This can be rewritten as the matrix system:
\begin{equation}
  \left[
    \begin{array}{c|c|c}
      \mathbf{z}_{01} & \mathbf{z}_{02} & \mathbf{z}_{12}
    \end{array}
  \right] =
  \mathbf{R}
  \left[
    \begin{array}{c|c|c}
      \mathbf{x}_0 - \mathbf{x}_1 &
      \mathbf{x}_0 - \mathbf{x}_2 &
      \mathbf{x}_1 - \mathbf{x}_2
    \end{array}
  \right]
\end{equation}

By introducing some more notations, the above matrix system emerges as follows
\begin{equation}
  \mathbf{Z} = \mathbf{R} \mathbf{X}
\end{equation}

Under the assumption that the three scene points $\mathbf{x}_i$ are not aligned,
the matrix $\mathbf{X}$ is then invertible and we can calculate the rotation as

\begin{equation}
  \mathbf{R} = \mathbf{Z} \mathbf{X}^{-1},
\end{equation}

And we can finally deduce $\mathbf{t}$ a posteriori since

\begin{equation}
  \mathbf{t} = \lambda_i \mathbf{y}_i - \mathbf{R} \mathbf{x}_i
\end{equation}

In my readings, I have learnt that the first method ever devised was discovered
by Grunert in 1841, who solved it for the case $N = 3$ (TODO CITE).

I won't try to review the literature exhaustively but let us quickly mention
that more recent methods have been proposed in the computer vision literature
for the general case (EPnP, UPnP to be cited) or for other particular case $N =
4$ (Quan and Lan).

Over the years, newer P3P methods have been proposed and are becoming more
efficient to compute. We will focus on reviewing Lambda-Twist
[@PerssonN:2018:eccv], which is one of the fastest P3P method if not the fastest
as of 2021.

### Lambda-Twist: a fast P3P solver.

Without loss of generality, Lambda-Twist assumes that each backprojected ray
$\mathbf{y}_i$ have unit norm, *i.e.*, $||\mathbf{y}_i||_2 = 1$, which otherwise
we renormalize as a preprocessing step.

Lambda-Twist starts by squaring the distance invariants, yielding the following
remarkable identity:

\begin{equation}
  \lambda_i^2 + \lambda_j^2 - 2 \mathbf{y}_i^T \mathbf{y}_j \lambda_i \lambda_j
  = || \mathbf{x}_i - \mathbf{x}_j ||_2^2
\end{equation}

#### Three Inhomogeneous Quadrics

[@PerssonN:2018:eccv] recognize three degenerate inhomogeneous quadratic forms
in the 3D vector $\mathbf{\Lambda} = \begin{bmatrix} \lambda_1 \\ \lambda_2 \\
\lambda_3 \end{bmatrix}$

By denoting the Euclidean squared distance by
\begin{equation}
  a_{ij} = || \mathbf{x}_i - \mathbf{x}_j ||_2^2,
\end{equation}
and the cosine of the angle between each backprojected light rays by
\begin{equation}
  b_{ij} = \mathbf{y}_i^T \mathbf{y}_j
\end{equation}

We can rewrite these into quadratic matrix form as
\begin{equation}
  \mathbf{\Lambda}^T \mathbf{M}_{ij} \mathbf{\Lambda} = a_{ij}
\end{equation}

where
\begin{equation}
  \mathbf{M}_{01} = \begin{bmatrix}
    1 & -b_{01} & 0 \\
    -b_{01} & 1 & 0 \\
    0 & 0 & 0 \\
  \end{bmatrix}
\end{equation}

\begin{equation}
  \mathbf{M}_{02} = \begin{bmatrix}
    1 & 0 & -b_{02} \\
    0 & 0 & 0 \\
    -b_{02} & 0 & 1 \\
  \end{bmatrix}
\end{equation}

\begin{equation}
  \mathbf{M}_{12} = \begin{bmatrix}
    0 & 0 & 0 \\
    0 & 1 & -b_{12} \\
    0 & -b_{12} & 1 \\
  \end{bmatrix}
\end{equation}

Let us take a closer look at these three matrices. Specifically we can
characterize these three quadratic form geometrically as follows.

- Each of them represents parabolic, elliptic or hyperbolic cylinders since in
  the $\Lambda$ 3-space, since the matrices are rank 2.
  In fact they are elliptic cylinders (parabolic in the worst case), since the
  discriminant of the conic is nonpositive
  \begin{equation}
    B^2 - 4AC = 4 b_{ij}^2 - 4 \leq 0
  \end{equation}
  since the cosine of unit vectors $b_{ij}$ verifies $-1 \leq b_{ij} =
  \mathbf{y}_i^T \mathbf{y}_j \leq 1$

  Unless we are dealing with 360 cameras (and even then), two backprojected
  light rays are unlikely to be collinear for two different image points. So we
  can safely assume that the discriminant is negative and that we are dealing
  are elliptic cylinders in the general case.

- the axis of each of these cylinders are mutually orthogonal as the zero column vector
  appears at different column index upon examination of the matrices.

#### Two Homogeneous Quadrics

The $\mathbf{\Lambda}$ that lie in the three inhomogeneous quadrics necessarily
lie in two homogeneous quadrics.

They are obtained by linearly combining the three inhomogeneous quadrics.

Specifically, by
\begin{equation}
  \mathbf{D}_0 = \mathbf{M}_{01} a_{12} - \mathbf{M}_{12} a_{01}
\end{equation}

\begin{equation}
  \mathbf{D}_1 = \mathbf{M}_{02} a_{12} - \mathbf{M}_{12} a_{02}
\end{equation}

We can easily see that algebraically that
\begin{equation}
  \mathbf{\Lambda}^T \mathbf{D}_i \mathbf{\Lambda} = 0
\end{equation}

These are the equations that characterizes the two homogeneous quadrics.

#### Cubic Equation

[@PerssonN:2018:eccv] goes another step further by linearly combining the two
homogeneous quadrics, which leads us to solve a cubic equation:

The paper wrongly reports the formula $c_2$ and $c_1$: they are actually swapped
and we can easily double-check this with SymPy.

TODO.


##### The Diagonalization Method

First let us explain the Eigen decomposition proposed by the paper.
- It first determines the eigenvalues by determining the roots of the
  characteristic polynomial.
- Then the method calculates the associated eigenvectors.

Now a few more words are necessary, the proposed eigen decomposition is not
entirely robust and a better approach has been proposed by David Eberly (TODO
cite). We follow Eberly's approach, which may introduce a few more operations
but remains still negligible. But the benefit outweighs the downside.

TODO.

##### The $\tau$ Polynomial.

The coefficients of the $\tau$ polynomial are wrongly reported. By manually
recalculating the coefficients and double-checking with SymPy, instead the
coefficients.

That might make the Gauss-Newton unnecessary as advised in the paper, or at
least require lot less iterations.
