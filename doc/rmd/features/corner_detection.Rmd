# Corners and Junctions

Detecting corners can be done in many different ways. One robust way to do so is
to analyze of the local distribution of image gradients at each pixel of the
image. From there, we can identify the dominant orientations of the gradients.

## Histogram of Gradients as Insight

:::fyi
OK, I agree this is not the real intuition that lectures or publications start
with but keep reading what I have to say.

I don't see why it can't be be a valid intuition.
:::

We can calculate one histogram of local gradients per pixel and then localize
the dominant gradient orientations which are localized at the histogram peaks.

Intuitively we expect to identify interpretable local image features:

- an edge if we count only $1$ dominant gradient orientation.
- a square-like corner if we count $2$ dominant peaks.
- a T-junction if we count $3$ dominant peaks.
- a chessboard X-corner if we count $4$ dominant peaks.
- and so on.

While, by design, the histogram cannot localize very precisely the corners, I
think it is important to be reminded that the histogram of gradients is still a
powerful tool in practice. And [@Lowe:2004:ijcv] describes a robust way to
identify the dominant gradient orientations.

## Small Shifts Inducing Large Intensity Changes

The histogram of gradients does not tell us precisely whether a pixel is located
a corner or a junction. It can only tell whether or not this pixel is close to a
corner and that depends on the size of the local window we choose when we build
the histogram of local gradients.

To localize corners accurately, [@Moravec:1980:phd] and [@HarrisS:1988:alvey]
look for pixels $\mathbf{x}$ where there exists a large intensity difference
$(I(\mathbf{x} + \mathbf{h}) - I(\mathbf{x}))^2$ for a **small and specific**
set of **nonzero** shifts $\mathbf{\Delta}$. I won't go into much details and I
will let you find out more by looking into [@Moravec:1980:phd]'s thesis.
[@HarrisS:1988:alvey]'s formulation is simple enough to get the whole picture
about corner detection.

Instead of considering an *ad-hoc* small set of nonzero shifts,
[@HarrisS:1988:alvey] does better by considering the sum of weighted squares of
intensity changes for any small shifts.

\begin{equation}
  \sum_\mathbf{h} w(\mathbf{h})
  \left( I(\mathbf{x} + \mathbf{h}) - I(\mathbf{x}) \right)^2
\end{equation}

Then surely this quantity must respond maximally at a corner location? Yes it is
the case in practise.

Let's observe the first-order Taylor expansion

\begin{equation}
  I(\mathbf{x} + \mathbf{h}) =
  I(\mathbf{x}) + \mathbf{h}^T \nabla I(\mathbf{x}) + o(\|\mathbf{h}\|)
\end{equation}

then it follows that the reweighted sum of squares is approximated as

\begin{equation}
  \sum_\mathbf{h} w(\mathbf{h})
  \ \mathbf{h}^T
  \left(
    \nabla I(\mathbf{x}) \nabla I(\mathbf{x})^T
  \right)
  \mathbf{h}
\end{equation}

As pointed by [@HarrisS:1988:alvey], we recognize the covariance matrix of local
gradients, which the corner detection will be based on. This is the so-called
*structure tensor*. Another innovation by [@HarrisS:1988:alvey] is to also
derive a **cornerness** score function from it. This function will score highest
to corners and even more so at their precise location. The cornerness function
solves the problem of corner localization.

Let us talk more in details about the structure tensor first and we will expand
a bit more on the cornerness later on.

## Structure Tensor

As we said it in the introduction, the structure tensor is a covariance matrix
of local gradients.

Let us define the structure tensor in the discrete domain first. Then we
redefine it in the continuous domain. The continuous definition is useful to
provide insights for a better and more efficient implementation in the discrete
domain.

### Discrete Domain

Formally we consider all image gradients $\nabla I(\mathbf{x} + \mathbf{h})$
within the image patch centered in $\mathbf{x}$ with radius $r$, that is, the
set of pixels $\mathbf{x} + \mathbf{h}$ such that $|| \mathbf{h} || < r$.
The gradients are reweighted by a weight function $w(\mathbf{h})$ which gives
them more importance if they are closer to $\mathbf{x}$. Classically, the
Gaussian kernel is used.

In the discrete domain, the structure tensor is written as

\begin{equation}
  \mathbf{M}(\mathbf{x}) =
  \displaystyle \sum_\mathbf{h} w(\mathbf{h})
  \begin{bmatrix}
    \left( \frac{\partial I
    (\mathbf{x} + \mathbf{h})}{\partial x} \right)^2 &&
    %
    \frac{\partial I(\mathbf{x} + \mathbf{h})}
         {\partial x}
    \frac{\partial I(\mathbf{x} + \mathbf{h})}
         {\partial y} \\
    %
    \frac{\partial I(\mathbf{x} + \mathbf{h})}
         {\partial x}
    \frac{\partial I(\mathbf{x} + \mathbf{h})}
         {\partial y} &&
    %
    \left( \frac{\partial I
    (\mathbf{x} + \mathbf{h})}{\partial y} \right)^2
  \end{bmatrix}
\end{equation}

### Continuous Domain

Since we mentioned the Gaussian kernel, which is **symmetric**, we can
generalize the definition in the continous domain as a convolution with any
distribution $w$.

\begin{equation}
  \mathbf{M}(\mathbf{x}) =
  \displaystyle \int w(\mathbf{h})
  \begin{bmatrix}
    \left( \frac{\partial I (\mathbf{x} -
    \mathbf{h})}{\partial x} \right)^2 &&
    %
    \frac{\partial I(\mathbf{x} - \mathbf{h})}
         {\partial x}
    \frac{\partial I(\mathbf{x} - \mathbf{h})}
         {\partial y} \\
    %
    \frac{\partial I(\mathbf{x} - \mathbf{h})}
         {\partial x}
    \frac{\partial I(\mathbf{x} - \mathbf{h})}
         {\partial y} &&
    %
    \left( \frac{\partial I (\mathbf{x} -
    \mathbf{h})}{\partial y} \right)^2 &&
  \end{bmatrix}
  d\mathbf{h}
\end{equation}

Now as a side note, in the sense of Lebesgue's integration, this definition
coincides with the discrete definition using a discrete measure.

We can re-express this more tersely, in functional notation with the $*$ symbol
to denote a convolution operation
\begin{equation}
  \mathbf{M} = \begin{bmatrix}
    w * \left( \frac{\partial I}{\partial x} \right)^2 &&
    %
    w *
    \left( \frac{\partial I}{\partial x} \frac{\partial I} {\partial y} \right) \\
    %
    w *
    \left( \frac{\partial I}{\partial x} \frac{\partial I} {\partial y} \right) &&
    %
    w *
    \left( \frac{\partial I}{\partial y} \right)^2
  \end{bmatrix}
\end{equation}

Again with a bit of linear algebra, we can rewrite this as

\begin{equation}
  \mathbf{M} = w * \left( \nabla I\ \nabla I^T \right)
\end{equation}

since
\begin{equation}
  \nabla I(\mathbf{x}) = \begin{bmatrix}
    \frac{\partial I(\mathbf{x})}{\partial x} \\
    \frac{\partial I(\mathbf{x})}{\partial y}
  \end{bmatrix}
\end{equation}

This form is convenient from an implementation point of view.

### Interpretation

Because the structure tensor is a covariance matrix, the structure
tensor should capture in principle only two principal directions of the image
gradients. The gradient directions are expected to be quasi-orthogonal.

This is perfect for a square-like corner where only two gradient orientations
should dominate. The structure tensor can also localize a edgel, only one
gradient orientation should dominate.

Indeed, the extraction of the eigenvectors will give us the two principal
directions of the gradients, and its associated eigenvalues $\lambda_1,
\lambda_2$ with $\lambda_1 > \lambda_2$  quantifies the "frequency" of these two
principal directions.

- If the local patch is **a uniform region**, the gradients are very small, the
  covariance matrix should be close to zero, i.e., $\lambda_i \approx 0$.
- If the local patch is on **an edge**, the covariance matrix should correspond
  to a very elongated ellipse geometrically. The ratio between the lowest and
  highest eigenvalues should be very small, i.e., each $\lambda_2 \ll \lambda_1$
- If the local patch is on **a corner**, then covariance matrix should
  correspond to a large circle. The ratio between the lowest and highest
  eigenvalues should be close should be close to $1$, i.e.,
  $\frac{\lambda_1}{\lambda_2} \approx 1$

In principle, the structure tensor should detect only these types of features,
corners or edgels. In practise however, it will respond strongly to junctions as
well. This is one problem of the structure tensor because this relies on the
assumption that edges are orthogonal...

### Other Practical Considerations

In practice the image $I$ is first convolved with a Gaussian kernel $g$ of
standard deviation $\sigma_D$. This is to reduce the aliasing and image noise.

\begin{equation}
  \mathbf{M} = g_{\sigma_I} * \left( \nabla I_{\sigma_D} * \ \nabla I_{\sigma_D}^T \right)
\end{equation}
where the convolved image with a gaussian kernel is denoted as
\begin{equation}
  I_{\sigma_D} = g_{\sigma_D} * I
\end{equation}

We need to mention another important consideration related to the **scale-space
theory**.
Assuming that the scale of the original image $I$ is exactly $1\ \textrm{pixel}$
($\textrm{px}$)^[Since the camera cannot capture details less than 1 pixel on
images in principle.], then the scale of the convolved image $I_{\sigma_D} =
g_{\sigma_D} * I$ is

\begin{equation}
  t = \sqrt{1 + \sigma_D^2}\ \textrm{px}
\end{equation}

This has an important consequence in practice.

1. Image details within a window of $t$
pixels are lost because of the Gaussian blur -- in principle.

2. The integration scale $\sigma_I$ in the structure tensor means that we are
considering local patches with radius $t \sigma_I = \sqrt{1 + \sigma_D^2}
\ \sigma_I$ to decide whether we see a
corner or not. This means that the best corners are separated by at least
$t \sigma_I$ pixels.


## Förstner Corner Operator

Harris's corner operator localizes corners with an accuracy within 1pixel. To
get a sub-pixel accuracy, we can use Förstner criterion.

**TODO**


## Cornerness Function

**TODO**


## Spiral Model

I learnt from [@ForstnerDS:2009:iccv] that the spiral model is an extension of
the structure tensor. This time, the structure is also parameterized with a 2D
rotation matrix parameterized by an angle $\alpha$ in the structure tensor.

\begin{equation}
  \mathbf{M}(\alpha) = w *
  \mathbf{R}_\alpha \nabla I \nabla I^T \mathbf{R}_\alpha^T
\end{equation}

