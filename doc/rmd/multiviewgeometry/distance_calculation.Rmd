## Distance Calculation From a Camera

This section provides an easily implementable method to calculate distance from
a camera. To calculate distances from a camera requires the knowledge of the
internal camera parameters.

### Motivating Example

Consider a camera at a fixed height $h$ above the ground slight looking
down due to a nonzero pitch angle $\theta$.

Consider a reference coordinate system centered in the camera center with the z-axis
still parallel to the ground plane where.

Let $M$ denote a point on the ground in this reference coordinate system.

\begin{equation}
  M = x\ \mathbf{i} + h\ \mathbf{j} + z\ \mathbf{k}
\end{equation}

The basis vectors of the reference coordinate system have the following
coordinates in the local camera coordinate system.

\begin{equation}
  \begin{array}{ccl}
  \mathbf{i} &=&  \mathbf{i}_C \\
  \mathbf{j} &=&  \cos\theta\ \mathbf{j}_C + \sin\theta\ \mathbf{k}_C \\
  \mathbf{k} &=& -\sin\theta\ \mathbf{j}_C + \cos\theta\ \mathbf{k}_C
  \end{array}
\end{equation}

Rewriting the coordinates of $M$ in the camera coordinates system

\begin{equation}
  \begin{array}{ccl}
  M &=& x\ \mathbf{i}_C +
        h (\cos\theta\ \mathbf{j}_C + \sin\theta\ \mathbf{k}_C) +
        z (-\sin\theta\ \mathbf{j}_C + \cos\theta\ \mathbf{k}_C) \\

  M &=& x\ \mathbf{i}_C +
        (h \cos\theta - z \sin\theta)\ \mathbf{j}_C +
        (h \sin\theta + z\cos\theta)\ \mathbf{k}_C \\
  \end{array}
\end{equation}

Thus in the camera coordinate system

\begin{equation}
  \begin{array}{ccl}
  x_C &=& x \\
  y_C &=& h \cos\theta - z \sin\theta \\
  z_C &=& h \sin\theta + z\cos\theta \\
  \end{array}
\end{equation}


The point $M$ is projected to the normalized camera plane. Let $(u,
v)$ denote its normalized camera coordinates.

By similar triangles it follows that

\begin{equation}
  \frac{u}{x_C} = \frac{v}{y_C} = \frac{1}{z_C}
\end{equation}


We can inject the equations to calculate $z$:

\begin{align*}
  v &= \frac{y_C}{z_C} \\
  v &= \frac{h \cos\theta - z \sin\theta}{h \sin\theta + z\cos\theta} \\
  v (h \sin\theta + z\cos\theta) &= h \cos\theta - z \sin\theta \\
  z (v\cos\theta + \sin\theta) &= h (\cos\theta - v \sin\theta)
\end{align*}

In the end:

\begin{equation}
  z = h \frac{\cos\theta - v \sin\theta}{\sin\theta + v\cos\theta} \\
\end{equation}


### Generalization to Any Global Rigid Transform

We can generalize elegantly the reasoning by means of linear algebra. And it
will not matter which angular direction $(\psi, \theta, \phi)$ the camera
is looking at.

Let us assume that the road is *planar*. Following the usual convention in the
automotive industry, without loss of generality, any point on the ground is at
height $z = 0$. Note this observation stays valid whether the vehicle
climbs or descends does not matter as long as the road is *planar*.

Suppose that we know the camera pose parameterised by the rigid body transform
$(\mathbf{R}, \mathbf{t})$ w.r.t. the vehicle coordinate system.

As said earlier, a ground point $M$ has more natural coordinates
$\mathbf{x} = (x, y, 0)$ in the vehicle coordinate system. Let
$\mathbf{x}'= (x', y', z')$ denote its coordinates in the camera
coordinate system. The rigid body transform relates the two vector quantities as
follows

\begin{equation}
  \mathbf{x} = \mathbf{R} \mathbf{x}' + \mathbf{t} \\
\end{equation}

The inverse rigid body transform is $(\mathbf{R}', \mathbf{t}')$
where:

\begin{equation}
  \begin{aligned}
  \mathbf{R}' &= \mathbf{R}^T \\
  \mathbf{t}' &= -\mathbf{R}^T \mathbf{t} \\
  \mathbf{x}' &= \mathbf{R}' \mathbf{x} + \mathbf{t}' \\
  \end{aligned}
\end{equation}

If the ground point is visible in the image at the following normalized
coordinates $(u, v)$, then using the basic proportionality theorem in
geometric optics:

\begin{equation}
  \frac{u}{x'} = \frac{v}{y'} = \frac{1}{z'},
\end{equation}

We can derive a system of two equations.

\begin{equation}
  \left\{ \begin{array}{lll}
  u z' - x' &=& 0 \\
  v z' - y' &=& 0 \\
  \end{array} \right.
\end{equation}

Expanding the matrix operation into a linear system:

\begin{equation}
  \mathbf{x}' = \mathbf{R}' \mathbf{x} + \mathbf{t}' \\
\end{equation}

yields

\begin{equation}
  \left\{ \begin{array}{lll}
  x' &=& r'_{11} x + r'_{12} y + r'_{13} z + t'_{1}\\
  y' &=& r'_{21} x + r'_{22} y + r'_{23} z + t'_{2}\\
  z' &=& r'_{31} x + r'_{32} y + r'_{33} z + t'_{3}\\
  \end{array} \right.
\end{equation}

Injecting these equations in the system of two equations yields

\begin{equation}
  \left\{ \begin{array}{lll}
  u (r'_{31} x + r'_{32} y + r'_{33} z + t'_{3}) -
    (r'_{11} x + r'_{12} y + r'_{13} z + t'_{1})  &=& 0 \\

  v (r'_{31} x + r'_{32} y + r'_{33} z + t'_{3}) -
    (r'_{21} x + r'_{22} y + r'_{23} z + t'_{2}) &=& 0\\
  \end{array} \right.
\end{equation}

Reordering

\begin{equation}
  \left\{ \begin{array}{lll}
  (u r'_{31} - r'_{11}) x - (u r'_{32} - r'_{12}) y + (u r'_{33} - r'_{13}) z
  &=& t'_{1} - u t'_{3} \\

  (v r'_{31} - r'_{21}) x - (v r'_{32} - r'_{22}) y + (v r'_{33} - r'_{23}) z
  &=& t'_{2} - v t'_{3}  \\
  \end{array} \right.
\end{equation}

```{proposition, name="Top-Down View and Distance Calculation"}
Because we are dealing with a ground point, $z = 0$ and we obtain an
invertible linear system:

\begin{equation}
  \left\{ \begin{array}{lll}
  (u r'_{31} - r'_{11}) x - (u r'_{32} - r'_{12}) y &=& t'_{1} - u t'_{3} \\
  (v r'_{31} - r'_{21}) x - (v r'_{32} - r'_{22}) y &=& t'_{2} - v t'_{3} \\
  \end{array} \right.
\end{equation}

This will determine the missing coordinates $x$ and $y$, which is
what we want.
```


### Generalization to Any Camera Model

So far our mathematical formulation assumes that the image formation is done via
perspective projection. In words, each pixel $\mathbf{u} =
\begin{bmatrix} u \\ v \end{bmatrix}$ of the image $I(\mathbf{u})$ is hit by the
3D light ray vector $-\mathbf{x}$, where $\mathbf{x} = \begin{bmatrix} x \\ y \\
1 \end{bmatrix}$, which is expressed in the camera frame.

Notice the negative sign in the light ray vector because the light ray is in
front in the camera and passes through the camera aperture to hit the camera
film plane.

If we know the camera calibration matrix $\mathbf{K}$, we can calculate
$\mathbf{x}$ for any pixel $\mathbf{u}$ as
\begin{equation}
  \mathbf{x} = \mathbf{K}^{-1} \begin{bmatrix} \mathbf{u} \\ 1 \end{bmatrix},
\end{equation}

From a mathematical point of view, it is not very practical to talk about the
light ray vector because of its negative sign. Instead we prefer to say that any
pixel $\mathbf{u}$ *backprojects* to the semi-line

\begin{equation}
  \{ \lambda \mathbf{x} : \lambda > 0 \}.
\end{equation}

In words any 3D scene point $\lambda \mathbf{x}$ of the semi-line are the only
points that

- are physically possible, and
- projects exactly to the point $\mathbf{u}$

because the true corresponding 3D scene point must be (1) *in front of the
camera* and (2) lies on this semi-line. The necessary condition $\lambda > 0$
ensures that the 3D scene point is in front of the camera and is what we call
the *cheirality* constraint in the literature.

The perspective projection is a strong assumption nowadays in computer vision
because it assumes the camera model is the ideal pinhole camera, in which case
the field-of-view (FOV) of the camera is far less than $180 \deg$.

Now what happens if the image is not formed from a normal photographic and
instead from a fisheye camera with FOV $> 180 \deg$? The fisheye camera is very
attractive in robotics and in surveillance applications because it can see the
scene behind it to quite some extent.
The image formation is more complicated and thus we cannot use the pinhole
camera model anymore.

However any well-formed mathematical camera model will
always allow us to retrieve the corresponding direction of the 3D light ray
$\mathbf{x}$ for any pixel $\mathbf{u}$.

In the case of the fisheye camera model, the direction $\mathbf{x}$ of the 3D
light ray is parameterized in spherical coordinates as
\begin{equation}
\mathbf{x} =
\begin{bmatrix}
  \cos \phi \cos \theta \\
  \sin \phi \cos \theta \\
  \sin \theta
\end{bmatrix}
\end{equation}

Then the image formation in the fisheye camera is summarized by the following formula
\begin{equation}
  r = 2 f \tan \frac{\theta}{2}
\end{equation}

where

- $r = \| \mathbf{u} - \mathbf{u}_0 \|_2$
- $u - u_0 = f \cos \phi$
- $v - v_0 = f \sin \phi$

TODO: finish this section.
