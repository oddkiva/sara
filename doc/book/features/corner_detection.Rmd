# Corners and Junctions

Traditional corner detectors are (accidentally by design) also junction
detectors as illustrated in Figures \@ref(fig:man-made-corners) and
\@ref(fig:natural-corners).

```{r}
#| echo: false
#| warning: false
#| label: man-made-corners
#| out.width: 80%
#| fig.align: center
#| fig.cap: >
#|   Corners found on man-made structures by Harris's corner detector
#|   implemented in Sara.
#|   Harris's detector responds well on a variety of corners:
#|   (1) sharp features on the roman digits printed on the clock,
#|   (2) T-junctions on tiles,
#|   (3) x-corners on metallic grids and so on.
knitr::include_graphics(paste0(getwd(), "/features/clock.jpg"))
```

```{r}
#| echo: false
#| warning: false
#| label: natural-corners
#| out.width: 80%
#| fig.align: center
#| fig.cap: >
#|   Corners found on natural structures by Harris's corner detector implemented
#|   in Sara.
#|   Harris's detector responds well on a variety of corners:
#|   (1) sharp features of the leaves,
#|   (2) false corners due to occlusion between leaves,
#|   (3) T-junctions on the leaf skeleton and so on.
knitr::include_graphics(paste0(getwd(), "/features/leaves.jpg"))
```

Detecting corners can be done in many different ways. One robust way to do so is
to analyze of the local distribution of image gradients at each pixel of the
image. From there, we can identify the dominant orientations of the gradients.

## Histogram of Gradients

:::fyi
OK, I agree this is not the real intuition that lectures or publications start
with but keep on reading what I have to say.

In this paragraph, I want to illustrate one recurring idea in image analysis
where very often we calculate image statistics in a small image patch to account
for the noisy image acquisition instead of considering a single data point.
:::

We can calculate one histogram of local gradients per pixel and then localize
the dominant gradient orientations which are localized at the histogram peaks.

Intuitively we expect to identify interpretable local image features:

- an edge if we count only $1$ dominant gradient orientation.
- a square-like corner if we count $2$ dominant peaks.
- a T-junction if we count $3$ dominant peaks.
- a chessboard X-corner if we count $4$ dominant peaks.
- and so on.

While by design the histogram does not localize very precisely the corners, the
histogram of gradients is a powerful tool to already categorize corners in basic
semantic groups. This can also prove useful in filtering unwanted corners. For
example, [@Lowe:2004:ijcv] describes a robust way to identify the dominant
gradient orientations.

## Small Shifts Inducing Large Intensity Changes

As the histogram of gradients is calculated on a small image patch, we can only tell
whether there is a corner inside the image patch but not where exactly the image
corners is located in pixel coordinates.

To localize corners accurately, [@Moravec:1980:phd] starts instead by look for
pixels $\mathbf{x}$ where there exists a large intensity difference

\begin{equation}
  \left( I(\mathbf{x} + \mathbf{h}) - I(\mathbf{x}) \right)^2
\end{equation}

for a **small and specific** set of **nonzero** shifts $\mathbf{h}$.^[I won't go
into much details and I will let you find out more by looking into
[@Moravec:1980:phd]'s thesis. We will talk more about [@HarrisS:1988:alvey].]

Now, instead of considering an *ad-hoc* small set of nonzero shifts,
[@HarrisS:1988:alvey] go further by considering the sum of **weighted** squares
of intensity differences for any small shift $\mathbf{h}$.

\begin{equation}
  \sum_\mathbf{h} w(\mathbf{h})
  \left( I(\mathbf{x} + \mathbf{h}) - I(\mathbf{x}) \right)^2
\end{equation}

In other words, let us instead compare every pixel intensity in a small image
patch to the central pixel intensity but also let us also assign a
**cornerness** score function to the pixel at the center of the image patch by
summation.

This is a much better idea because now we have just introduced a function that
can be optimized in a mathematical sense. This function will score higher as the
image patch center get closer to the precise corner location. Thus solving the
problem of corner localization.

Then because $\mathbf{h}$ is small, we can approximate the summand in the
cornerness function with a first-order Taylor expansion

\begin{equation}
  I(\mathbf{x} + \mathbf{h}) =
  I(\mathbf{x}) + \mathbf{h}^\top \nabla I(\mathbf{x}) + o(\|\mathbf{h}\|)
\end{equation}

so that we can re-define the cornerness function as

\begin{equation}
  \sum_\mathbf{h} w(\mathbf{h})
  \ \mathbf{h}^\top
  \left(
    \nabla I(\mathbf{x}) \nabla I(\mathbf{x})^\top
  \right)
  \mathbf{h},
\end{equation}

where the nabla operator $\nabla$ expresses the gradient as a column-vector
\begin{equation}
  \nabla I = \begin{bmatrix}
    \frac{\partial I}{\partial x} \\
    \frac{\partial I}{\partial y}
  \end{bmatrix}.
\end{equation}

As pointed out by [@HarrisS:1988:alvey], we recognize the covariance matrix of
local gradients. This is the so-called *structure tensor*.

Let us talk more in details about the structure tensor first and we will expand
a bit more on the cornerness later on.

## Structure Tensor

The structure tensor has a geometric interpretation as I will expand on it in a
bit.

Let us define the structure tensor first in the discrete domain, then in the
continuous domain. The continuous definition provides us insights for a better
and more efficient implementation in the discrete domain.

### Discrete Domain

Formally we consider all image gradients $\nabla I(\mathbf{x} + \mathbf{h})$
within the image patch centered in $\mathbf{x}$ with radius $r$, that is, the
set of pixels $\mathbf{x} + \mathbf{h}$ such that $|| \mathbf{h} || < r$.
The gradients are reweighted by a weight function $w(\mathbf{h})$ which gives
them more importance if they are closer to $\mathbf{x}$. Classically, the
Gaussian kernel is used.

In the discrete domain, the structure tensor is written as

\begin{equation}
  \mathbf{M}(\mathbf{x}) =
  \displaystyle \sum_\mathbf{h} w(\mathbf{h})
  \begin{bmatrix}
    \left( \frac{\partial I
    (\mathbf{x} + \mathbf{h})}{\partial x} \right)^2 &&
    %
    \frac{\partial I(\mathbf{x} + \mathbf{h})}
         {\partial x}
    \frac{\partial I(\mathbf{x} + \mathbf{h})}
         {\partial y} \\
    %
    \frac{\partial I(\mathbf{x} + \mathbf{h})}
         {\partial x}
    \frac{\partial I(\mathbf{x} + \mathbf{h})}
         {\partial y} &&
    %
    \left( \frac{\partial I
    (\mathbf{x} + \mathbf{h})}{\partial y} \right)^2
  \end{bmatrix}
\end{equation}

### Continuous Domain

Since we mentioned the Gaussian kernel, which is **symmetric**, we can
generalize the definition to the continous domain as a convolution with any
distribution $w$.

\begin{equation}
  \mathbf{M}(\mathbf{x}) =
  \displaystyle \int w(\mathbf{h})
  \begin{bmatrix}
    \left( \frac{\partial I (\mathbf{x} -
    \mathbf{h})}{\partial x} \right)^2 &&
    %
    \frac{\partial I(\mathbf{x} - \mathbf{h})}
         {\partial x}
    \frac{\partial I(\mathbf{x} - \mathbf{h})}
         {\partial y} \\
    %
    \frac{\partial I(\mathbf{x} - \mathbf{h})}
         {\partial x}
    \frac{\partial I(\mathbf{x} - \mathbf{h})}
         {\partial y} &&
    %
    \left( \frac{\partial I (\mathbf{x} -
    \mathbf{h})}{\partial y} \right)^2 &&
  \end{bmatrix}
  d\mathbf{h}
\end{equation}

As a side note, Lebesgue's definition of integration unifies the definitions in
discrete and continuous domains, as we simply have have to consider a discrete
measure.

We can re-express this more tersely, in functional notation with the $*$ symbol
to denote a convolution operation

\begin{equation}
  \mathbf{M} = w * \left( \nabla I\ \nabla I^\top \right)
\end{equation}

### Geometric Interpretation

Because the structure tensor is a covariance matrix, the structure tensor should
capture in principle only two principal directions of the image gradients.
Specifically, for a square-like corner, the two major gradient directions are
expected to be quasi-orthogonal.

Likewise the structure tensor can also localize an edgel, and in this case only
one gradient orientation should dominate.

Indeed the extraction of the eigenvectors will give us the two principal
directions of the gradients, and its associated eigenvalues $\lambda_1,
\lambda_2$ with $\lambda_1 > \lambda_2$  quantifies the "frequency" of these two
principal directions.

- If the local patch is **a uniform region**, the gradients are very small, the
  covariance matrix should be close to zero, i.e., $\lambda_i \approx 0$.
- If the local patch is on **an edge**, the covariance matrix should correspond
  to a very elongated ellipse geometrically. The ratio between the lowest and
  highest eigenvalues should be very small, i.e., each $\lambda_2 \ll \lambda_1$
- If the local patch is on **a corner**, then covariance matrix should
  correspond to a large circle. The ratio between the lowest and highest
  eigenvalues should be close should be close to $1$, i.e.,
  $\frac{\lambda_1}{\lambda_2} \approx 1$

In principle, the structure tensor should detect only these types of features,
corners or edgels. In practise however, it will respond strongly to junctions as
well. This is one problem of the structure tensor because this relies on the
assumption that edges are orthogonal...

## Cornerness Function

Based on the geometric interpretation, [@HarrisS:1988:alvey] prefer to redefine
again the cornerness function as

\begin{equation}
  C = \det(\mathbf{M}) - \kappa \mathrm{trace}(\mathbf{M})
\end{equation}

In practice, I have found that $\kappa = 0.04$ works very well in my experiments
and found little reason to change it. [@HarrisS:1988:alvey] suggests a range
with this value being the this lower bound.


## Practical Considerations

### Localization Accuracy

In practice the image $I$ is first convolved with a Gaussian kernel $g$ of
standard deviation $\sigma_D$. This is to reduce the aliasing and image noise.

\begin{equation}
  \mathbf{M} = g_{\sigma_I} * \left( \nabla I_{\sigma_D} \ \nabla I_{\sigma_D}^\top \right)
\end{equation}
where the convolved image with a gaussian kernel is denoted as
\begin{equation}
  I_{\sigma_D} = g_{\sigma_D} * I
\end{equation}

We need to mention another important consideration related to the **scale-space
theory**. Assuming that the scale of the original image $I$ is exactly $1\
\textrm{pixel}$ ($\textrm{px}$)^[Since the camera cannot capture details less
than 1 pixel on images in principle.], then the scale of the convolved image
$I_{\sigma_D} = g_{\sigma_D} * I$ is

\begin{equation}
  t = \sqrt{1 + \sigma_D^2}\ \textrm{px}
\end{equation}

This has an important consequence in practice.

1. Image details within a window of $t$
pixels are lost because of the Gaussian blur -- in principle.

2. The integration scale $\sigma_I$ in the structure tensor means that we are
considering local patches with radius $t \sigma_I = \sqrt{1 + \sigma_D^2}
\ \sigma_I$ to decide whether we see a
corner or not. This means that the best corners are separated by at least
$t \sigma_I$ pixels.

### Remarks About Efficient Implementations

In practise, the convenient form that really allows for an optimized
implementation is the following one

\begin{equation}
  \mathbf{M} = \begin{bmatrix}
    w * \left( \frac{\partial I}{\partial x} \right)^2 &&
    %
    w *
    \left( \frac{\partial I}{\partial x} \frac{\partial I} {\partial y} \right) \\
    %
    w *
    \left( \frac{\partial I}{\partial x} \frac{\partial I} {\partial y} \right) &&
    %
    w *
    \left( \frac{\partial I}{\partial y} \right)^2
  \end{bmatrix}
\end{equation}

Because the structure tensor matrix is symmetric, efficient implementations
calculate only the upper-triangular terms. They perform the following operations
in the following order:

1. The derivative maps $\frac{\partial I}{\partial x}$ and
   $\frac{\partial I}{\partial y}$.
2. The product maps
   $\left(\frac{\partial I}{\partial x}\right)^2$,
   $\left(\frac{\partial I}{\partial y}\right)^2$ and
   $\frac{\partial I}{\partial x} \frac{\partial I}{\partial y}$
3. The convolved maps
   $w * \left( \frac{\partial I}{\partial x} \right)^2$,
   $w * \left( \frac{\partial I}{\partial y} \right)^2$ and
   $w * \frac{\partial I}{\partial x} \frac{\partial I}{\partial y}$

On any platforms, the trickiest operation to optimize is the convolution. This
is especially true on CPU architectures, where it can be difficult to find the
optimal scheduling as pointed out in [@RaganKelleyBAPDA:2013:pldi].


## Förstner's Junction Operator

Harris's detector localizes corners with an accuracy of $1$ pixel at best. To
get a sub-pixel accuracy, we can refine the corner location using Förstner
criterion.

Förstner's idea comes from the observation that a good corner should be lying on
the two dominant edges, if we look at a small patch centered at the corner
location $\mathbf{x}$.

So we just said that $\mathbf{x}$ must be an edgel. Let's discuss two cases.

- If a neighboring pixel $\mathbf{x}'$ is also an edgel, we expect
  that the direction vector $\mathbf{h}$ is a good approximation of the
  (quasi-straight) edge curve and should be normal to the image gradient $\nabla
  I(\mathbf{x}')$.

  That means that the dot product between that the edge direction and the image
  gradient should be very small.
- If a neighboring pixel is not an edgel, its image gradients should be close to
  zero and it will not bring any information.

Now, since the corner location $\mathbf{x}$ is quantized, we can refine its
location by minimizing the sum of square dot products over all points in the
patches. The sum of squares can be reweighted by say a Gaussian kernel $w(.)$ to
give more importance to pixels $\mathbf{x}'$ closer to the approximate corner
location $\mathbf{x}$.

And Förstner's criterion becomes

\begin{equation}
  \displaystyle \min_\mathbf{x}
  \sum_\mathbf{x'} w\left(\mathbf{x} - \mathbf{x}'\right)
  \left\{
    \left(\mathbf{x} - \mathbf{x}' \right)^\top \nabla I(\mathbf{x}')
  \right\}^2
\end{equation}

where the neighboring pixels $\mathbf{x}'$ are in a small image patch
$\|\mathbf{x} - \mathbf{x}'\| < r$.

In fact, we can calculate the sum of square dot-products at every single pixel
of the image as every corner would correspond to a local minimum of this such
criterion, But Harris's corner detection method is computationally more
efficient.

:::note
Until now, I have talked about corners but we can easily convince ourselves that
that Förstner's criterion works for any complex junctions, say an x-corner,
a T-junction.
:::


## Spiral Model

I learnt from [@ForstnerDS:2009:iccv] that the spiral model is an extension of
the structure tensor. This time, the structure is also parameterized with a 2D
rotation matrix parameterized by an angle $\alpha$ in the structure tensor.

\begin{equation}
  \mathbf{M}(\alpha) = w *
  \mathbf{R}_\alpha \nabla I \nabla I^\top \mathbf{R}_\alpha^\top
\end{equation}

